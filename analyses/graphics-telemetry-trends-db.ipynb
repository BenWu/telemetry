{"cells":[{"cell_type":"code","source":["# The entry-point to this analysis is at the very bottom of this file.\n# Look for the call to DoUpdate()."],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["from __future__ import division\nimport ujson as json\nimport numpy as np\nimport operator\nimport json, time, sys, os\nimport datetime\nfrom moztelemetry import get_pings, get_pings_properties, get_one_ping_per_client\nfrom moztelemetry.dataset import Dataset\ndef fmt_date(d):\n    return d.strftime(\"%Y%m%d\")\ndef jstime(d):\n    return time.mktime(d.timetuple())\ndef repartition(pipeline):\n    return pipeline.repartition(MaxPartitions).cache()\n\nMaxPartitions = sc.defaultParallelism * 4\n\n# Keep this small (0.00001) for fast backfill testing.\nWeeklyFraction = 0.003\n\n# Amount of days Telemetry keeps.\nMaxHistoryInDays = datetime.timedelta(days=210)\n\n# Bucket we'll drop files into on S3. If this is None, we won't attempt any\n# S3 uploads, and the analysis will start from scratch.\nS3_BUCKET = None\nGITHUB_REPO = 'https://raw.githubusercontent.com/FirefoxGraphics/moz-gfx-telemetry'\n\n# Going forward we only care about sessions from Firefox 53+, since it\n# is the first release to not support Windows XP and Vista, which disorts\n# our statistics.\nMinFirefoxVersion = '53'\n\n# List of jobs allowed to have a first-run (meaning no S3 content).\nBrandNewJobs = []\n\n# If true, backfill up to MaxHistoryInDays rather than the last update.\nForceMaxBackfill = False\n\n# Local directory on DBFS to store the trend data\nDBFS_PATH = 'gfx/trends'\n\n# The path used for Python IO\nABSOLUTE_PATH = '/dbfs/{0}'.format(DBFS_PATH)\n\n# The output path on S3\nS3_OUTPUT_BUCKET = 's3://telemetry-public-analysis-2/gfx/telemetry-data'"],"metadata":{"collapsed":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["#dbutils.fs.rm(DBFS_PATH, recurse=True)\n\nprint('Creating local directory {0} on DBFS'.format(DBFS_PATH))\ndbutils.fs.mkdirs(DBFS_PATH)\n\nfrom os import walk\n\nf = []\nfor (dirpath, dirnames, filenames) in walk(ABSOLUTE_PATH):\n  f.extend(dirnames)\n  f.extend(filenames)\n  break\n\nprint('Current contents of {0}: {1}'.format(ABSOLUTE_PATH, f))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Creating local directory gfx/trends on DBFS\nCurrent contents of /dbfs/gfx/trends: [&#39;trend-firefox-v2.json&#39;, &#39;trend-windows-arch-v2.json&#39;, &#39;trend-windows-compositors-v2.json&#39;, &#39;trend-windows-d2d-v2.json&#39;, &#39;trend-windows-d3d11-v2.json&#39;, &#39;trend-windows-device-gen-amd-v2.json&#39;, &#39;trend-windows-device-gen-intel-v2.json&#39;, &#39;trend-windows-device-gen-nvidia-v2.json&#39;, &#39;trend-windows-vendors-v2.json&#39;, &#39;trend-windows-versions-v2.json&#39;]\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Use this block to temporarily change parameters above.\n# ForceMaxBackfill = True\n#WeeklyFraction = 0.00001\n#S3_BUCKET = None\nMaxHistoryInDays = datetime.timedelta(days=210)\n#BrandNewJobs = []"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["if os.environ[\"DATABRICKS_RUNTIME_VERSION\"] and S3_BUCKET:\n  raise Exception(\"S3 sync is not supported on Databricks\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["ArchKey =               'environment/build/architecture'\nFxVersionKey =          'environment/build/version'\nWow64Key =              'environment/system/isWow64'\nCpuKey =                'environment/system/cpu'\nGfxAdaptersKey =        'environment/system/gfx/adapters'\nGfxFeaturesKey =        'environment/system/gfx/features'\nOSNameKey =             'environment/system/os/name'\nOSVersionKey =          'environment/system/os/version'\nOSServicePackMajorKey = 'environment/system/os/servicePackMajor'"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["FirstValidDate = datetime.datetime.utcnow() - MaxHistoryInDays"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Log spam eats up disk space, so we disable it.\ndef quiet_logs(sc):\n  logger = sc._jvm.org.apache.log4j\n  logger.LogManager.getLogger(\"org\").setLevel(logger.Level.ERROR)\n  logger.LogManager.getLogger(\"akka\").setLevel(logger.Level.ERROR)\nquiet_logs(sc)"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["# This is the entry-point to grabbing reduced, preformatted pings.\ndef FetchAndFormat(start_date, end_date):\n    pings = GetRawPings(start_date, end_date)\n    pings = ReduceRawPings(pings)\n    pings = get_one_ping_per_client(pings)\n    pings = pings.map(Validate)\n    pings = pings.filter(lambda p: p.get('valid', False) == True)\n    return pings.cache()\n    \ndef GetRawPings(start_date, end_date):\n    if isinstance(start_date, datetime.datetime):\n        start_date = fmt_date(start_date)\n    if isinstance(end_date, datetime.datetime):\n        end_date = fmt_date(end_date)\n    \n    def match_date(date):\n        return start_date <= date <= end_date\n            \n    ds = Dataset.from_source('telemetry-sample')\n    ds = ds.where(docType = 'main')\n    ds = ds.where(appName = 'Firefox')\n    ds = ds.where(appVersion = lambda version: version >= MinFirefoxVersion)\n    ds = ds.where(submissionDate = match_date)\n    \n    # We hit the telemetry-sample dataset, which is a 1% sample of pings, so we multiply the configured fraction by 100.\n    modified_fraction = WeeklyFraction * 100\n    \n    return ds.records(sc, sample = modified_fraction)\n\ndef ReduceRawPings(pings):\n    return get_pings_properties(pings, [\n        'clientId',\n        'creationDate',\n        ArchKey,\n        Wow64Key,\n        CpuKey,\n        FxVersionKey,\n        GfxAdaptersKey,\n        GfxFeaturesKey,\n        OSNameKey,\n        OSVersionKey,\n        OSServicePackMajorKey,\n    ])\n\n# Transform each ping to make it easier to work with in later stages.\ndef Validate(p):\n    try:\n        name = p.get(OSNameKey) or 'w'\n        version = p.get(OSVersionKey) or '0'\n        if name == 'Linux':\n            p['OSVersion'] = None\n            p['OS'] = 'Linux'\n            p['OSName'] = 'Linux'\n        elif name == 'Windows_NT':\n            spmaj = p.get(OSServicePackMajorKey) or '0'\n            p['OSVersion'] = version + '.' + str(spmaj)\n            p['OS'] = 'Windows-' + version + '.' + str(spmaj)\n            p['OSName'] = 'Windows'\n        elif name == 'Darwin':\n            p['OSVersion'] = version\n            p['OS'] = 'Darwin-' + version\n            p['OSName'] = 'Darwin'\n        else:\n            p['OSVersion'] = version\n            p['OS'] = '{0}-{1}'.format(name, version)\n            p['OSName'] = name\n    except:\n        return p\n    \n    p['valid'] = True\n    return p"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# Profiler for debugging. Use in a |with| clause.\nclass Prof(object):\n    level = 0\n    \n    def __init__(self, name):\n        self.name = name\n    def __enter__(self):\n        self.sout('Starting {0}... '.format(self.name))\n        self.start = datetime.datetime.now()\n        Prof.level += 1\n        return None\n    def __exit__(self, type, value, traceback):\n        Prof.level -= 1\n        self.end = datetime.datetime.now()\n        self.sout('... {0}: {1}s'.format(self.name, (self.end - self.start).total_seconds()))\n    def sout(self, s):\n        sys.stdout.write(('##' * Prof.level) + ' ')\n        sys.stdout.write(s)\n        sys.stdout.write('\\n')\n        sys.stdout.flush()"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["# Helpers.\ndef fix_vendor(vendorID):\n    if vendorID == u'Intel Open Source Technology Center':\n        return u'0x8086'\n    return vendorID\n\ndef get_vendor(ping):\n    try:\n        adapter = ping[GfxAdaptersKey][0]\n        return fix_vendor(adapter['vendorID'])\n    except:\n        return 'unknown'"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["# A TrendBase encapsulates the data needed to visualize a trend.\n# It has four functions:\n#    prepare    (download from cache)\n#    willUpdate (check if update is needed)\n#    update     (add analysis data for a week of pings)\n#    finish     (upload back to cache)\nclass TrendBase(object):\n    def __init__(self, name):\n        super(TrendBase, self).__init__()\n        self.name = '{0}-v2.json'.format(name)\n    \n    # Called before analysis starts.\n    def prepare(self):\n        print('Preparing {0}'.format(self.name))\n        return True\n    \n    # Called before querying pings for the week for the given date. Return\n    # false to indicate that this should no longer receive updates.\n    def willUpdate(self, date):\n        raise Exception('Return true or false')\n   \n    def update(self, pings, **kwargs):\n        raise Exception('NYI')\n        \n    def finish(self):\n        pass\n"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["# Given a list of trend objects, query weeks from the last sunday\n# and iterating backwards until no trend object requires an update.\ndef DoUpdate(trends):\n    root = TrendGroup('root', trends)\n    root.prepare()\n        \n    # Start each analysis slice on a Sunday.\n    latest = MostRecentSunday()\n    end = latest\n    \n    while True:\n        start = end - datetime.timedelta(7)\n        assert latest.weekday() == 6\n        \n        if not root.willUpdate(start):\n            break\n        \n        try:\n            with Prof('fetch {0}'.format(start)) as _:\n                pings = FetchAndFormat(start, end)\n        except:\n            if not ForceMaxBackfill:\n                raise\n        \n        with Prof('compute {0}'.format(start)) as _:\n            if not root.update(pings, start_date = start, end_date = end):\n                break\n            \n        end = start\n        \n    root.finish()\n    \ndef MostRecentSunday():\n    now = datetime.datetime.utcnow()\n    this_morning = datetime.datetime(now.year, now.month, now.day)\n    if this_morning.weekday() == 6:\n        return this_morning\n    diff = datetime.timedelta(0 - this_morning.weekday() - 1)\n    return this_morning + diff"],"metadata":{"collapsed":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["# A TrendGroup is a collection of TrendBase objects. It lets us\n# group similar trends together. For example, if five trends all\n# need to filter Windows pings, we can filter for Windows pings\n# once and cache the result, rather than redo the filter each\n# time.\n#\n# Trend groups keep an \"active\" list of trends that will probably\n# need another update. If any trend stops requesting data, it is\n# removed from the active list.\nclass TrendGroup(TrendBase):\n    def __init__(self, name, trends):\n        super(TrendGroup, self).__init__(name)\n        self.trends = trends\n        self.active = []\n    \n    def prepare(self):\n        self.trends = [trend for trend in self.trends if trend.prepare()]\n        self.active = self.trends[:]\n        return len(self.trends) > 0\n            \n    def willUpdate(self, date):\n        self.active = [trend for trend in self.active if trend.willUpdate(date)]\n        return len(self.active) > 0\n    \n    def update(self, pings, **kwargs):\n        pings = pings.cache()\n        self.active = [trend for trend in self.active if trend.update(pings, **kwargs)]\n        return len(self.active) > 0\n            \n    def finish(self):\n        for trend in self.trends:\n            trend.finish()\n            \n# A Trend object takes a new set of pings for a week's worth of data,\n# analyzes it, and adds the result to the trend set. Trend sets are\n# cached in S3 as JSON.\n#\n# If the latest entry in the cache covers less than a full week of\n# data, the entry is removed so that week can be re-queried.\nclass Trend(TrendBase):\n    def __init__(self, filename):\n        super(Trend, self).__init__(filename)\n        self.s3_path = os.path.join(S3_BUCKET, self.name) if S3_BUCKET else None\n        self.local_path = os.path.join(ABSOLUTE_PATH, self.name)\n        self.cache = None\n        self.lastFullWeek = None\n        self.newDataPoints = []\n        \n    def query(self, pings):\n        raise Exception('NYI')\n        \n    def willUpdate(self, date):\n        if date < FirstValidDate:\n            return False\n        if self.lastFullWeek is not None and date <= self.lastFullWeek:\n            return False\n        return True\n    \n    def prepare(self):\n        self.cache = self.fetch_json()\n        if self.cache is None:\n            self.cache = {\n                'created': jstime(datetime.datetime.utcnow()),\n                'trend': [],\n            }\n        \n        # Make sure trends are sorted in ascending order.\n        self.cache['trend'] = self.cache['trend'] or []            \n        self.cache['trend'] = sorted(self.cache['trend'], key = lambda o: o['start'])\n        \n        if len(self.cache['trend']) and not ForceMaxBackfill:\n            lastDataPoint = self.cache['trend'][-1]\n            lastDataPointStart = datetime.datetime.utcfromtimestamp(lastDataPoint['start'])\n            lastDataPointEnd = datetime.datetime.utcfromtimestamp(lastDataPoint['end'])\n            print(lastDataPoint, lastDataPointStart, lastDataPointEnd)\n            if lastDataPointEnd - lastDataPointStart < datetime.timedelta(7):\n                # The last data point had less than a full week, so we stop at the\n                # previous week, and remove the incomplete datapoint.\n                self.lastFullWeek = lastDataPointStart - datetime.timedelta(7)\n                self.cache['trend'].pop()\n            else:\n                # The last data point covered a full week, so that's our stopping\n                # point.\n                self.lastFullWeek = lastDataPointStart\n                print(self.lastFullWeek)\n        \n        return True\n    \n    # Optional hook - transform pings before querying.\n    def transformPings(self, pings):\n        return pings\n    \n    def update(self, pings, start_date, end_date, **kwargs):\n        with Prof('count {0}'.format(self.name)):\n            pings = self.transformPings(pings)\n            count = pings.count()\n        if count == 0:\n            print('WARNING: no pings in RDD')\n            return False\n        \n        with Prof('query {0} (count: {1})'.format(self.name, count)):\n            data = self.query(pings)\n        \n        self.newDataPoints.append({\n            'start': jstime(start_date),\n            'end': jstime(end_date),\n            'total': count,\n            'data': data,\n        })\n        return True\n            \n    def finish(self):\n        # If we're doing a maximum backfill, remove points from the cache that are\n        # after the least recent data point that we newly queried.\n        if ForceMaxBackfill and len(self.newDataPoints):\n            stopAt = self.newDataPoints[-1]['start']\n            lastIndex = None\n            for index, entry in enumerate(self.cache['trend']):\n                if entry['start'] >= stopAt:\n                    lastIndex = index\n                    break\n            if lastIndex is not None:\n                self.cache['trend'] = self.cache['trend'][:lastIndex]\n        \n        # Note: the backfill algorithm in DoUpdate() walks in reverse, so dates\n        # will be accumulated in descending order. The final list should be in\n        # ascending order, so we reverse.\n        self.cache['trend'] += self.newDataPoints[::-1]\n        \n        text = json.dumps(self.cache)\n\n        print(\"Writing file {0}\".format(self.local_path, text))\n        with open(self.local_path, 'w') as fp:\n            fp.write(text)\n\n        if self.s3_path:\n            try:\n                os.system(\"aws s3 cp {0} {1}\".format(self.local_path, self.s3_path))\n            except Exception as e:\n                print(\"Failed s3 upload: {0}\".format(e))\n            \n    def fetch_json(self):\n        print(\"Reading file {0}\".format(self.local_path))\n        if self.s3_path:\n            try:\n                os.system(\"aws s3 cp {0} {1}\".format(self.s3_path, self.local_path))\n                with open(self.local_path, 'r') as fp:\n                    return json.load(fp)\n                return None\n            except:\n                if self.name not in BrandNewJobs:\n                    raise\n                return None\n        else:\n            try:\n                with open(self.local_path, 'r') as fp:\n                    return json.load(fp)\n            except:\n                pass\n        return None"],"metadata":{"collapsed":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["class FirefoxTrend(Trend):\n    def __init__(self):\n        super(FirefoxTrend, self).__init__('trend-firefox')\n        \n    def query(self, pings, **kwargs):\n        def get_version(p):\n            v = p.get(FxVersionKey, None)\n            if v is None or not isinstance(v, str):\n                return 'unknown'\n            return v.split('.')[0]\n        return pings.map(lambda p: (get_version(p),)).countByKey()"],"metadata":{"collapsed":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["class WindowsGroup(TrendGroup):\n    def __init__(self, trends):\n        super(WindowsGroup, self).__init__('Windows', trends)\n        \n    def update(self, pings, **kwargs):\n        pings = pings.filter(lambda p: p['OSName'] == 'Windows')\n        return super(WindowsGroup, self).update(pings, **kwargs)\n\nclass WinverTrend(Trend):\n    def __init__(self):\n        super(WinverTrend, self).__init__('trend-windows-versions')\n        \n    def query(self, pings):\n        return pings.map(lambda p: (p['OSVersion'],)).countByKey()\n    \nclass WinCompositorTrend(Trend):\n    def __init__(self):\n        super(WinCompositorTrend, self).__init__('trend-windows-compositors')\n        \n    def willUpdate(self, date):\n        # This metric didn't ship until Firefox 43.\n        if date < datetime.datetime(2015, 11, 15):\n            return False\n        return super(WinCompositorTrend, self).willUpdate(date)\n        \n    def query(self, pings):\n        return pings.map(lambda p: (self.get_compositor(p),)).countByKey()\n    \n    @staticmethod\n    def get_compositor(p):\n        features = p.get(GfxFeaturesKey, None)\n        if features is None:\n            return 'none'\n        return features.get('compositor', 'none')\n    \nclass WinArchTrend(Trend):\n    def __init__(self):\n        super(WinArchTrend, self).__init__('trend-windows-arch')\n        \n    def query(self, pings):\n        return pings.map(lambda p: (self.get_os_bits(p),)).countByKey()\n    \n    @staticmethod\n    def get_os_bits(p):\n        arch = p.get(ArchKey, 'unknown')\n        if arch == 'x86-64':\n            return '64'\n        elif arch == 'x86':\n            if p.get(Wow64Key, False):\n                return '32_on_64'\n            return '32'\n        return 'unknown'\n\n# This group restricts pings to Windows Vista+, and must be inside a\n# group that restricts pings to Windows.\nclass WindowsVistaPlusGroup(TrendGroup):\n    def __init__(self, trends):\n        super(WindowsVistaPlusGroup, self).__init__('Windows Vista+', trends)\n        \n    def update(self, pings, **kwargs):\n        pings = pings.filter(lambda p: not p['OSVersion'].startswith('5.1'))\n        return super(WindowsVistaPlusGroup, self).update(pings, **kwargs)\n\nclass Direct2DTrend(Trend):\n    def __init__(self):\n        super(Direct2DTrend, self).__init__('trend-windows-d2d')\n    \n    def query(self, pings):\n        return pings.map(lambda p: (self.get_d2d(p),)).countByKey()\n    \n    def willUpdate(self, date):\n        # This metric didn't ship until Firefox 43.\n        if date < datetime.datetime(2015, 11, 15):\n            return False\n        return super(Direct2DTrend, self).willUpdate(date)\n    \n    @staticmethod\n    def get_d2d(p):\n        try:\n            status = p[GfxFeaturesKey]['d2d']['status']\n            if status != 'available':\n                return status\n            return p[GfxFeaturesKey]['d2d']['version']\n        except:\n            return 'unknown'\n        \nclass Direct3D11Trend(Trend):\n    def __init__(self):\n        super(Direct3D11Trend, self).__init__('trend-windows-d3d11')\n    \n    def query(self, pings):\n        return pings.map(lambda p: (self.get_d3d11(p),)).countByKey()\n    \n    def willUpdate(self, date):\n        # This metric didn't ship until Firefox 43.\n        if date < datetime.datetime(2015, 11, 15):\n            return False\n        return super(Direct3D11Trend, self).willUpdate(date)\n    \n    @staticmethod\n    def get_d3d11(p):\n        try:\n            d3d11 = p[GfxFeaturesKey]['d3d11']\n            if d3d11['status'] != 'available':\n                return d3d11['status']\n            if d3d11.get('warp', False):\n                return 'warp'\n            return d3d11['version']\n        except:\n            return 'unknown'\n        \nclass WindowsVendorTrend(Trend):\n    def __init__(self):\n        super(WindowsVendorTrend, self).__init__('trend-windows-vendors')\n        \n    def query(self, pings):\n        return pings.map(lambda p: (get_vendor(p),)).countByKey()"],"metadata":{"collapsed":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["# Device generation trend - a little more complicated, since we download\n# the generation database to produce a mapping.\nclass DeviceGenTrend(Trend):\n    deviceMap = None\n    \n    def __init__(self, vendor, vendorName):\n        super(DeviceGenTrend, self).__init__('trend-windows-device-gen-{0}'.format(vendorName))\n        self.vendorBlock = None\n        self.vendorID = vendor\n        \n    def prepare(self):\n        # Grab the vendor -> device -> gen map.\n        if not DeviceGenTrend.deviceMap:\n            import requests\n            resp = requests.get('{0}/master/www/gfxdevices.json'.format(GITHUB_REPO))\n            DeviceGenTrend.deviceMap = resp.json()\n        self.vendorBlock = DeviceGenTrend.deviceMap[self.vendorID]\n        return super(DeviceGenTrend, self).prepare()\n    \n    def transformPings(self, pings):\n        return pings.filter(lambda p: get_vendor(p) == self.vendorID)\n        \n    def query(self, pings):\n        return pings.map(lambda p: (self.get_gen(p),)).countByKey()\n    \n    def get_gen(self, p):\n        adapter = p[GfxAdaptersKey][0]\n        deviceID = adapter.get('deviceID', 'unknown')\n        if deviceID not in self.vendorBlock:\n            return 'unknown'\n        return self.vendorBlock[deviceID][0]"],"metadata":{"collapsed":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["DoUpdate([\n    FirefoxTrend(),\n    WindowsGroup([\n        WinverTrend(),\n        WinCompositorTrend(),\n        WinArchTrend(),\n        WindowsVendorTrend(),\n        WindowsVistaPlusGroup([\n            Direct2DTrend(),\n            Direct3D11Trend(),\n        ]),\n        DeviceGenTrend(u'0x8086', 'intel'),\n        DeviceGenTrend(u'0x10de', 'nvidia'),\n        DeviceGenTrend(u'0x1002', 'amd'),\n    ])\n])"],"metadata":{"collapsed":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-168048&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     12</span>         DeviceGenTrend<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">u&#39;0x8086&#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#39;intel&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span>         DeviceGenTrend<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">u&#39;0x10de&#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#39;nvidia&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">---&gt; 14</span><span class=\"ansi-red-fg\">         </span>DeviceGenTrend<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">u&#39;0x1002&#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#39;amd&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     15</span>     ])\n<span class=\"ansi-green-intense-fg ansi-bold\">     16</span> ])\n\n<span class=\"ansi-green-fg\">&lt;command-168043&gt;</span> in <span class=\"ansi-cyan-fg\">DoUpdate</span><span class=\"ansi-blue-fg\">(trends)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     24</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     25</span>         <span class=\"ansi-green-fg\">with</span> Prof<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;compute {0}&#39;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>start<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">as</span> _<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 26</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> root<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span>pings<span class=\"ansi-blue-fg\">,</span> start_date <span class=\"ansi-blue-fg\">=</span> start<span class=\"ansi-blue-fg\">,</span> end_date <span class=\"ansi-blue-fg\">=</span> end<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     27</span>                 <span class=\"ansi-green-fg\">break</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span> \n\n<span class=\"ansi-green-fg\">&lt;command-168044&gt;</span> in <span class=\"ansi-cyan-fg\">update</span><span class=\"ansi-blue-fg\">(self, pings, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     25</span>     <span class=\"ansi-green-fg\">def</span> update<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> pings<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     26</span>         pings <span class=\"ansi-blue-fg\">=</span> pings<span class=\"ansi-blue-fg\">.</span>cache<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 27</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>active <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>trend <span class=\"ansi-green-fg\">for</span> trend <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>active <span class=\"ansi-green-fg\">if</span> trend<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span>pings<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span>         <span class=\"ansi-green-fg\">return</span> len<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>active<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">0</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span> \n\n<span class=\"ansi-green-fg\">&lt;command-168044&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;listcomp&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     25</span>     <span class=\"ansi-green-fg\">def</span> update<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> pings<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     26</span>         pings <span class=\"ansi-blue-fg\">=</span> pings<span class=\"ansi-blue-fg\">.</span>cache<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 27</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>active <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>trend <span class=\"ansi-green-fg\">for</span> trend <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>active <span class=\"ansi-green-fg\">if</span> trend<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span>pings<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span>         <span class=\"ansi-green-fg\">return</span> len<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>active<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">0</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span> \n\n<span class=\"ansi-green-fg\">&lt;command-168046&gt;</span> in <span class=\"ansi-cyan-fg\">update</span><span class=\"ansi-blue-fg\">(self, pings, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     <span class=\"ansi-green-fg\">def</span> update<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> pings<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span>         pings <span class=\"ansi-blue-fg\">=</span> pings<span class=\"ansi-blue-fg\">.</span>filter<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> p<span class=\"ansi-blue-fg\">:</span> p<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;OSName&#39;</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#39;Windows&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 7</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> super<span class=\"ansi-blue-fg\">(</span>WindowsGroup<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span>pings<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      9</span> <span class=\"ansi-green-fg\">class</span> WinverTrend<span class=\"ansi-blue-fg\">(</span>Trend<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">&lt;command-168044&gt;</span> in <span class=\"ansi-cyan-fg\">update</span><span class=\"ansi-blue-fg\">(self, pings, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     25</span>     <span class=\"ansi-green-fg\">def</span> update<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> pings<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     26</span>         pings <span class=\"ansi-blue-fg\">=</span> pings<span class=\"ansi-blue-fg\">.</span>cache<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 27</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>active <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>trend <span class=\"ansi-green-fg\">for</span> trend <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>active <span class=\"ansi-green-fg\">if</span> trend<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span>pings<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span>         <span class=\"ansi-green-fg\">return</span> len<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>active<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">0</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span> \n\n<span class=\"ansi-green-fg\">&lt;command-168044&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;listcomp&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     25</span>     <span class=\"ansi-green-fg\">def</span> update<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> pings<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     26</span>         pings <span class=\"ansi-blue-fg\">=</span> pings<span class=\"ansi-blue-fg\">.</span>cache<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 27</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>active <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>trend <span class=\"ansi-green-fg\">for</span> trend <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>active <span class=\"ansi-green-fg\">if</span> trend<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span>pings<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span>         <span class=\"ansi-green-fg\">return</span> len<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>active<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">0</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span> \n\n<span class=\"ansi-green-fg\">&lt;command-168044&gt;</span> in <span class=\"ansi-cyan-fg\">update</span><span class=\"ansi-blue-fg\">(self, pings, start_date, end_date, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     94</span>         <span class=\"ansi-green-fg\">with</span> Prof<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;count {0}&#39;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     95</span>             pings <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>transformPings<span class=\"ansi-blue-fg\">(</span>pings<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 96</span><span class=\"ansi-red-fg\">             </span>count <span class=\"ansi-blue-fg\">=</span> pings<span class=\"ansi-blue-fg\">.</span>count<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     97</span>         <span class=\"ansi-green-fg\">if</span> count <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     98</span>             print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;WARNING: no pings in RDD&#39;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansi-cyan-fg\">count</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1094</span>         <span class=\"ansi-cyan-fg\">3</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1095</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">-&gt; 1096</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>mapPartitions<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> i<span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">[</span>sum<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1</span> <span class=\"ansi-green-fg\">for</span> _ <span class=\"ansi-green-fg\">in</span> i<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>sum<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1097</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1098</span>     <span class=\"ansi-green-fg\">def</span> stats<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansi-cyan-fg\">sum</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1085</span>         <span class=\"ansi-cyan-fg\">6.0</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1086</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">-&gt; 1087</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>mapPartitions<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">[</span>sum<span class=\"ansi-blue-fg\">(</span>x<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>fold<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">,</span> operator<span class=\"ansi-blue-fg\">.</span>add<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1088</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1089</span>     <span class=\"ansi-green-fg\">def</span> count<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansi-cyan-fg\">fold</span><span class=\"ansi-blue-fg\">(self, zeroValue, op)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    956</span>         <span class=\"ansi-red-fg\"># zeroValue provided to each partition is unique from the one provided</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    957</span>         <span class=\"ansi-red-fg\"># to the final reduce call</span>\n<span class=\"ansi-green-fg\">--&gt; 958</span><span class=\"ansi-red-fg\">         </span>vals <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>mapPartitions<span class=\"ansi-blue-fg\">(</span>func<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>collect<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    959</span>         <span class=\"ansi-green-fg\">return</span> reduce<span class=\"ansi-blue-fg\">(</span>op<span class=\"ansi-blue-fg\">,</span> vals<span class=\"ansi-blue-fg\">,</span> zeroValue<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    960</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansi-cyan-fg\">collect</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    829</span>         <span class=\"ansi-red-fg\"># Default path used in OSS Spark / for non-credential passthrough clusters:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    830</span>         <span class=\"ansi-green-fg\">with</span> SCCallSiteSync<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>context<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">as</span> css<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 831</span><span class=\"ansi-red-fg\">             </span>sock_info <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>ctx<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>PythonRDD<span class=\"ansi-blue-fg\">.</span>collectAndServe<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jrdd<span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    832</span>         <span class=\"ansi-green-fg\">return</span> list<span class=\"ansi-blue-fg\">(</span>_load_from_socket<span class=\"ansi-blue-fg\">(</span>sock_info<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_jrdd_deserializer<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    833</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     61</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>             s <span class=\"ansi-blue-fg\">=</span> e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">.</span>toString<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job 11081 cancelled as part of cancellation of all jobs\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2355)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:2290)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply$mcVI$sp(DAGScheduler.scala:1000)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:1000)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:1000)\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n\tat org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:1000)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2546)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2510)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:893)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2243)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2265)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2309)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:961)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:960)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:210)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor974.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["# Copy the trend data from DBFS to S3\ndbutils.fs.cp(DBFS_PATH, S3_OUTPUT_BUCKET, recurse=True)\ndbutils.fs.ls(S3_OUTPUT_BUCKET)"],"metadata":{},"outputs":[],"execution_count":19}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.12","nbconvert_exporter":"python","file_extension":".py"},"name":"graphics-telemetry-trends","notebookId":156368,"kernelspec":{"display_name":"Python [default]","language":"python","name":"python2"},"anaconda-cloud":{}},"nbformat":4,"nbformat_minor":0}
