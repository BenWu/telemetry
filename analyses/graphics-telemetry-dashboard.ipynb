{"nbformat_minor": 0, "cells": [{"execution_count": 2, "cell_type": "code", "source": "import ujson as json\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport plotly.plotly as py\nimport operator\nimport json\nfrom __future__ import division\n\nfrom moztelemetry import get_pings, get_pings_properties, get_one_ping_per_client\n\n%pylab inline\n\nMaxPartitions = sc.defaultParallelism * 4", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Populating the interactive namespace from numpy and matplotlib\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 3, "cell_type": "code", "source": "def fmt_date(d):\n    return d.strftime(\"%Y%m%d\")\n\nTimeWindow = 14\nPingFraction = 0.05\n\n# Get two weeks worth of pings across all channels. For testing, we\n# currently select a very small subset.\nt1 = fmt_date(datetime.datetime.now() - datetime.timedelta(TimeWindow + 2)) # go back 16 days\nt2 = fmt_date(datetime.datetime.now() - datetime.timedelta(2)) # go back 2 days\nall_pings = get_pings(sc, app=\"Firefox\", build_id=(t1, t2), fraction=PingFraction)", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 4, "cell_type": "code", "source": "pings = get_pings_properties(all_pings, [\n  \"clientID\",\n  \"environment/build/version\",\n  \"environment/system/os/name\",\n  \"environment/system/os/version\",\n  \"environment/system/os/servicePackMajor\",\n  \"environment/system/os/servicePackMinor\",\n  \"environment/system/gfx/adapters\",\n  \"histograms/DEVICE_RESET_REASON\",\n  \"histograms/GRAPHICS_SANITY_TEST\",\n])\npings = get_one_ping_per_client(pings)\n\n# Transform each ping to make it easier to work with in later stages.\ndef Validate(p):\n    name = p.get(\"environment/system/os/name\") or 'w'\n    version = p.get(\"environment/system/os/version\") or '0'\n    if name == 'Linux':\n        p['OSVersion'] = None\n        p['OS'] = 'Linux'\n        p['OSName'] = 'Linux'\n    elif name == 'Windows_NT':\n        spmaj = p.get(\"environment/system/os/servicePackMajor\") or '0'\n        p['OSVersion'] = version + '.' + str(spmaj)\n        p['OS'] = 'Windows-' + version + '.' + str(spmaj)\n        p['OSName'] = 'Windows'\n    elif name == 'Darwin':\n        p['OSVersion'] = version\n        p['OS'] = 'Darwin-' + version\n        p['OSName'] = 'Darwin'\n    else:\n        return p\n    \n    # Telemetry data isn't guaranteed to be well-formed so unfortunately\n    # we have to do some validation on it. If we get to the end, we set\n    # p['valid'] to True, and this gets filtered over later. In addition\n    # we have a wrapper below to help fetch strings that may be null.\n    if not p.get(\"environment/build/version\", None):\n        return p\n    p['FxVersion'] = p[\"environment/build/version\"].split('.')[0]\n    \n    # Verify that we have at least one adapter.\n    try:\n        adapter = p[\"environment/system/gfx/adapters\"][0]\n    except:\n        return p\n    if adapter is None or not hasattr(adapter, '__getitem__'):\n        return p\n    \n    def T(obj, key):\n        return obj.get(key, None) or 'Unknown'\n    \n    # We store the device ID as a vendor/device string, because the device ID\n    # alone is not enough to determine whether the key is unique.\n    #\n    # We also merge 'Intel Open Source Technology Center' with the device ID\n    # that should be reported, 0x8086, for simplicity.\n    vendorID = T(adapter, 'vendorID')\n    if vendorID == u'Intel Open Source Technology Center':\n        p['vendorID'] = u'0x8086'\n    else:\n        p['vendorID'] = vendorID\n    p['deviceID'] = u'{0}/{1}'.format(p['vendorID'], T(adapter, 'deviceID'))\n    p['driverVersion'] = u'{0}/{1}'.format(p['vendorID'], T(adapter, 'driverVersion'))\n    if adapter['driverVersion']:\n        p['driverShortVersion'] = '{0}/{1}'.format(p['vendorID'], '.'.join(T(adapter, 'driverVersion').split('.')[0:3]))\n    else:\n        p['driverShortVersion'] = '{0}/Unknown'.format(p['vendorID'])\n        \n    p['valid'] = True\n    return p\n\n# Transform step.\nannotated_pings = pings.map(Validate)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 5, "cell_type": "code", "source": "# Filter out pings we didn't understand.\nAllData = annotated_pings.filter(lambda p: p.get('valid', False) == True)\nAllData = AllData.cache()\n\n# Windows gets some preferential breakdown treatment.\nWindowsSubset = AllData.filter(lambda p: p['OSName'] == 'Windows')\nWindowsSubset = WindowsSubset.cache()", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 6, "cell_type": "code", "source": "# Take each key in |b| and add it to |a|, accumulating its value into\n# |a| if it already exists.\ndef combiner(a, b):\n    result = a\n    for key in b:\n        countA = a.get(key, 0)\n        countB = b[key]\n        result[key] = countA + countB\n    return result\n\n# Return an aggregation based on combiner.\ndef aggregation(data, fn):\n    view = data.map(fn)\n    return view.reduceByKey(combiner)\n\n# After reduceByKey(combiner), we get a mapping like:\n#  key => { variable => value }\n#\n# This function collapses 'variable' instances below a threshold into\n# a catch-all identifier ('Other').\ndef coalesce_to_n_items(agg, max_items):\n    obj = []\n    for superkey, breakdown in agg:\n        if len(breakdown) <= max_items:\n            obj += [(superkey, breakdown)]\n            continue\n        items = sorted(breakdown.items(), key=lambda obj: obj[1], reverse=True)\n        new_breakdown = {k: v for k, v in items[0:max_items]}\n        total = 0\n        for k, v in items[max_items:]:\n            total += v\n        if total:\n            new_breakdown['Other'] = new_breakdown.get('Other', 0) + total\n        obj += [(superkey, new_breakdown)]\n    return obj\n\ndef union_pipelines(a, b):\n    if a is None:\n        return b\n    return a + b", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 7, "cell_type": "code", "source": "def map_x_to_y(data, sourceKey, destKey):\n    def extract(p):\n        return (p[sourceKey], { p[destKey]: 1 })\n    return aggregation(data, extract)\n\ndef map_x_to_count(data, sourceKey):\n    def extract(p):\n        return (p[sourceKey],)\n    return data.map(extract).countByKey()\n\n# Results by operating system.\nOSToVendor = map_x_to_y(AllData, 'OSName', 'vendorID')\nOSToDevice = map_x_to_y(AllData, 'OSName', 'deviceID')\nOSShare = map_x_to_count(AllData, 'OSName')\n\n# Results by Windows version.\nWindowsToVendor = map_x_to_y(WindowsSubset, 'OSVersion', 'vendorID')\nWindowsToDevice = map_x_to_y(WindowsSubset, 'OSVersion', 'deviceID')\nWindowsToDriver = map_x_to_y(WindowsSubset, 'OSVersion', 'driverVersion')\nWindowsShare = map_x_to_count(WindowsSubset, 'OSVersion')\nDriverShare = map_x_to_count(WindowsSubset, 'driverVersion')\n\n# Results by Firefox version.\nFxToVendor = map_x_to_y(AllData, 'FxVersion', 'vendorID')\nFxToDevice = map_x_to_y(AllData, 'FxVersion', 'deviceID')\nFxShare = map_x_to_count(AllData, 'FxVersion')\n\n# Top-level stats.\nVendorShare = map_x_to_count(AllData, 'vendorID')\nDeviceShare = map_x_to_count(AllData, 'deviceID')", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 8, "cell_type": "code", "source": "#############################\n# Perform the TDR analysis. #\n#############################\nNumTDRReasons = 8\ndef ping_has_tdr_for(p, reason):\n    return p['histograms/DEVICE_RESET_REASON'][reason] > 0\n\n# Specialized version of map_x_to_y, for TDRs. We cast to int because for\n# some reason the values Spark returns do not serialize with JSON.\ndef map_reason_to_vendor(p, reason, destKey):\n    return (int(reason), { p[destKey]: int(p['histograms/DEVICE_RESET_REASON'][reason]) })\ndef map_vendor_to_reason(p, reason, destKey):\n    return (p[destKey], { int(reason): int(p['histograms/DEVICE_RESET_REASON'][reason]) })\n\n# Filter out pings that do not have any TDR data. We expect this to be a huge reduction\n# in the sample set, and the resulting partition count gets way off. We repartition\n# immediately for performance.\nTDRSubset = WindowsSubset.filter(lambda p: p.get('histograms/DEVICE_RESET_REASON', None) is not None)\nTDRSubset = TDRSubset.repartition(MaxPartitions)\nTDRSubset = TDRSubset.cache()\n\n# For each TDR reason, get a list tuple of (reason, vendor => resetCount). Then\n# we combine these into a single series.\nreason_to_vendor_tuples = None\nvendor_to_reason_tuples = None\nfor reason in xrange(1, NumTDRReasons):\n    subset = TDRSubset.filter(lambda p: ping_has_tdr_for(p, reason))\n    subset = subset.cache()\n    \n    tuples = subset.map(lambda p: map_reason_to_vendor(p, reason, 'vendorID'))\n    reason_to_vendor_tuples = union_pipelines(reason_to_vendor_tuples, tuples)\n    \n    tuples = subset.map(lambda p: map_vendor_to_reason(p, reason, 'vendorID'))\n    vendor_to_reason_tuples = union_pipelines(vendor_to_reason_tuples, tuples)\n\nTDRReasonToVendor = reason_to_vendor_tuples.reduceByKey(combiner, MaxPartitions)\nTDRVendorToReason = vendor_to_reason_tuples.reduceByKey(combiner, MaxPartitions)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 9, "cell_type": "code", "source": "#########################\n# Sanity test analysis. #\n#########################\nSANITY_TEST_PASSED = 0\nSANITY_TEST_FAILED_RENDER = 1\nSANITY_TEST_FAILED_VIDEO = 2\nSANITY_TEST_CRASHED = 3\nSANITY_TEST_LAST_VALUE = 4\n\nsanity_test_pings = WindowsSubset.filter(lambda p: p.get('histograms/GRAPHICS_SANITY_TEST', None) is not None)\nsanity_test_pings = sanity_test_pings.repartition(MaxPartitions)\nsanity_test_pings = sanity_test_pings.cache()\n\n# Aggregate the sanity test data.\nSanityTestResults = sanity_test_pings.map(lambda p: p['histograms/GRAPHICS_SANITY_TEST']).reduce(lambda x, y: x + y)\n\nsanity_test_by_vendor = None\nsanity_test_by_os = None\nsanity_test_by_device = None\nsanity_test_by_driver = None\nfor value in xrange(SANITY_TEST_FAILED_RENDER, SANITY_TEST_LAST_VALUE):\n    subset = sanity_test_pings.filter(lambda p: p['histograms/GRAPHICS_SANITY_TEST'][value] > 0)\n    subset = subset.cache()\n\n    tuples = subset.map(lambda p: (value, { p['vendorID']: int(p['histograms/GRAPHICS_SANITY_TEST'][value]) }))\n    sanity_test_by_vendor = union_pipelines(sanity_test_by_vendor, tuples)\n    \n    tuples = subset.map(lambda p: (value, { p['OS']: int(p['histograms/GRAPHICS_SANITY_TEST'][value]) }))\n    sanity_test_by_os = union_pipelines(sanity_test_by_os, tuples)\n    \n    tuples = subset.map(lambda p: (value, { p['deviceID']: int(p['histograms/GRAPHICS_SANITY_TEST'][value]) }))\n    sanity_test_by_device = union_pipelines(sanity_test_by_device, tuples)\n    \n    tuples = subset.map(lambda p: (value, { p['driverShortVersion']: int(p['histograms/GRAPHICS_SANITY_TEST'][value]) }))\n    sanity_test_by_driver = union_pipelines(sanity_test_by_driver, tuples)\n    \nSanityTestByVendor = sanity_test_by_vendor.reduceByKey(combiner)\nSanityTestByOS = sanity_test_by_os.reduceByKey(combiner)\nSanityTestByDevice = sanity_test_by_device.reduceByKey(combiner)\nSanityTestByDriver = sanity_test_by_driver.reduceByKey(combiner)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 10, "cell_type": "code", "source": "# Helper for writing files.\ndef Export(obj, filename):\n    with open(filename, 'w') as fp:\n        json.dump(obj, fp)", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 11, "cell_type": "code", "source": "# Start writing stuff out.\nExport({\n    'vendors': OSToVendor.collect(),\n    'devices': OSToDevice.collect(),\n}, 'os-statistics.json')\n        \nExport({\n    'vendors': WindowsToVendor.collect(),\n    'devices': WindowsToDevice.collect(),\n    'driversByVersion': WindowsToDriver.collect(),\n    'driverShare': DriverShare,\n}, 'windows-statistics.json')\n    \nExport({\n    'vendors': FxToVendor.collect(),\n    'devices': FxToDevice.collect(),\n}, 'fx-statistics.json')\n    \nExport({\n    'os': OSShare,\n    'windows': WindowsShare,\n    'firefox': FxShare,\n    'vendors': VendorShare,\n    'devices': DeviceShare,\n    'totalPings': pings.count(),\n    'validPings': AllData.count(),\n    'timeWindow': TimeWindow,\n    'pingFraction': PingFraction,\n}, 'general-statistics.json')\n", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 12, "cell_type": "code", "source": "# Write TDR statistics.\nExport({\n    'tdrPings': TDRSubset.count(),\n    'windowsPings': WindowsSubset.count(),\n    'reasonToVendor': TDRReasonToVendor.collect(),\n    'vendorToReason': TDRVendorToReason.collect(),\n}, 'tdr-statistics.json')", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 13, "cell_type": "code", "source": "# Write Sanity Test statistics.\nExport({    \n    'totalSessions': WindowsSubset.count(),\n    'sanityTestPings': sanity_test_pings.count(),\n    'results': [int(value) for value in SanityTestResults],\n    'byVendor': SanityTestByVendor.collect(),\n    'byOS': SanityTestByOS.collect(),\n    'byDevice': coalesce_to_n_items(SanityTestByDevice.collect(), 10),\n    'byDriver': coalesce_to_n_items(SanityTestByDriver.collect(), 10),\n}, 'sanity-test-statistics.json')", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.9", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}